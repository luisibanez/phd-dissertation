%% This LaTeX-file was created by <ibanez> Tue Apr 18 02:08:19 2000
%% LyX 0.12 (C) 1995-1998 by Matthias Ettrich and the LyX Team

%% Do not edit this file unless you know what you are doing.
\documentclass[american]{book}
\usepackage[T1]{fontenc}
\usepackage{babel}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}
\usepackage{graphics}
\usepackage{subfigure}

\makeatletter


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\newcommand{\LyX}{L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\spacefactor1000}

\makeatother

\begin{document}

\tableofcontents


\chapter{Détection de surfaces}


\section{Généralités}

La détection de surfaces dans les volumes des données est basée sur la généralisation
des méthodes utilisées en imagerie bidimensionnelle. Le concept de contour relève
le caractère de transition ou changement de l'intensité de niveaux de gris dans
l'image. La généralité de cette définition conduit au fait la sortie d'un processus
de détection de contours ne rend pas toujours les résultats escomptés.

Nous présentons dans ce chapitre notre étude concernant divers types de détecteurs
de contours appliqués au problème de la détection des surfaces dans les volumes
de données. Les détecteurs que nous avons choisi ont été mis dans un cadre comparatif
permettant d'évaluer sa performance aussi bien du point de vue de temps de calcul
que de précision de la détection. Ils ont tous un paramètre a régler associé
au lissage qui s'appl\.{\i}que préalablement à la détection du contour. Ce
lissage adapte d'une certaine manière l'échelle à laquelle le contour est cherché.
Le test à été fait en utilisant pour chaque détecteur la valeur optimale de
son paramètre.


\subsection{Les types de profil}

La notion de transition des niveaux de gris, étant très vague, elle peut se
présenter de diverses manières \cite{ComparingMethods}. la figure~\ref{fig:profiles}
illustre différents profils de niveaux de gris extraits le long d'une ligne
dans des volumes de données Scanner X. La ligne tracée dans les images signale
la région d'où le profil a été pris.

\begin{figure}
{\centering \subfigure[Articulation du coude]{\resizebox*{4.4cm}{4.4cm}{\includegraphics{data/profile1img.eps}}} 
\subfigure[Profil de niveaux de gris]{\resizebox*{5.5cm}{4.4cm}{\includegraphics{data/profile1.eps}}}  \par}

{\centering \subfigure[Articulation Scapulo-Humerale]{\resizebox*{4.4cm}{4.4cm}{\includegraphics{data/profile2img.eps}}} 
\subfigure[Profile de niveux de gris]{\resizebox*{5.5cm}{4.4cm}{\includegraphics{data/profile2.eps}}}  \par}

{\centering \subfigure[Articulation Coxo-Femorale]{\resizebox*{4.4cm}{4.4cm}{\includegraphics{data/profile3img.eps}}} 
\subfigure[Profile de niveaux de gris]{\resizebox*{5.5cm}{4.4cm}{\includegraphics{data/profile3.eps}}} \par}


\caption{\label{fig:profiles}Le contour comme changement d'intensité du signal.}
\end{figure} 

Ces profils illustrent un des problèmes importants de la détection de surfaces
: le fait de constater que \emph{visuellement} l'observateur humain n'éprouve
aucune difficulté pour la détermination des contours tandis que les algorithmes
de traitement d'image ont souvent des performances insatisfaisantes. La facilité
avec laquelle l'observateur réalise cette tâche, conduit souvent à sous-estimer
la complication de son automatisation.


\subsection{La notion de multi-échelle\label{sec:multi-echelle}}

Le changement d'intensité peut être considéré aussi bien à un niveau très local
qu'entre des regions éloignées. La différence entre les deux cas étant simplement
une relation d'échelle spatiale considérée. Tout processus de détection de contours
doit d'une façon ou d'une autre s'ajuster à la grandeur de la zone de transition.

En général, il ne suffit pas de choisir une échelle particulière, au contraire,
il faut considérer et analyser toute une suite d'échelles. L'introduction du
concept de multi-échelle a été faite par Marr et Hildreth suite à l'étude du
système visuel humain \cite{MarrHildreth}\cite{Marr}.

Les approches multi-échelle se réalisent en trois étapes :

\begin{itemize}
\item Filtrage passe-bas pour choisir l'échelle d'intêret
\item Détection de contours par des opérateurs dérivatifs
\item Analyse de l'ensemble des échelles pour interpréter l'information.
\end{itemize}
Dans notre travail, seulement les deux premières étapes ont été retenues, car
la troisième s'est montrée insuffisante pour résoudre nos besoins d'extraction
de formes. Notamment au niveau articulaire où les distances qui séparent les
surfaces des pieces osseuses confrontées sont de l'ordre de la taille du voxel. 

L'application du filtrage passe bas a aussi pour effet une réduction du bruit
dans l'image, sous l'hypothèse que le bruit a un spectre principalement riche
en hautes fréquences.


\subsection{Les artéfacts en Tomographie}

Nous sommes particulièrement concernés ici par l'extraction de surface à partir
des images tomographiques. Cettes images ont des caractéristiques qui leur sont
propres et qui doivent être prises en compte au moment de s'engager dans un
procès de détection de surfaces.

Une des caractéristiques importantes des images de tomographie est le fait qu'elles
sont obtenues suite au processus de reconstruction à partir de projections \cite{Herman3Dimaging}\cite{HermanRFP}.
Les méthodes de reconstruction ont des limitations liées au nombre réduit de
projections réellement utilisées pour récupérer le volume de données. Les artéfacts
typiques en images des tomographie sont:

\begin{itemize}
\item la décorrelation dans l'axe de balayage du scanner
\item les lignes résiduelles de projections
\end{itemize}
Le premier est la conséquence du fait que le volume de données est reconstruit
coupe par coupe. Les coupes ne sont pas toujours cohérentes entre elles dans
l'axe de balayage. La constatation la plus directe de cette décorrélation est
la variabilité d'artéfacts linéaires entre les coupes voisines. 

Le second artéfact provient du fait d'utiliser l'information d'une projection
dans une direction pour la redistribuer sur tous les voxels qui ont dû intervenir
dans l'absorption de la radiation au moment de l'acquisition de la projection.
La figure (\ref{fig:artefacts}) montre un ensemble de coupes avec leurs Laplaciens
respectifs. Les lignes rouges démarquent les endroits d'où les coupes des deux
autres axes ont été prises. 

Ces artéfacts sont souvent interprétés comme du bruit, particulièrement quand
ils sont vus dans les coupes des axes perpendiculaires à l'axe de balayage (à
cause de la décorrélation entre coupes), mais cette interprétation s'avere incorrecte
dans la mesure où, les notions de décorrelation spatiale propres au bruit ne
sont pas satisfaites, et ne peuvent pas être décrits correctement par des distributions
statistiques. Les artéfacts ont un caractère non-linéaire dans la mesure ou
leur orientations et intensités dépendent directement du contenu du volume des
données.

\begin{figure}
{\centering \subfigure[Coupe axe X]{\resizebox*{4.5cm}{4.5cm}{\includegraphics{data/artx.eps}}} 
\subfigure[Laplacian X]{\resizebox*{4.5cm}{4.5cm}{\includegraphics{data/artxLap.eps}}} \par}

{\centering \subfigure[Coupe axe Y]{\resizebox*{4.5cm}{4.5cm}{\includegraphics{data/arty.eps}}} 
\subfigure[Laplacian  Y]{\resizebox*{4.5cm}{4.5cm}{\includegraphics{data/artyLap.eps}}} \par}

{\centering \subfigure[Coupe Z]{\resizebox*{4.5cm}{4.5cm}{\includegraphics{data/artz.eps}}} 
\subfigure[Laplacian Z]{\resizebox*{4.5cm}{4.5cm}{\includegraphics{data/artzLap.eps}}} \par}


\caption{\label{fig:artefacts}Artéfacts linéaires et décorrélation des coupes dans
l'axe z (axe du balayage du tomographe).}
\end{figure}Les artéfacts linéaires peuvent être appréciés dans l'image (\ref{fig:artefacts}f)
comme irradiant depuis une source située à droite . Ces structures linéaires
sont vues comme du bruit dans l'image (\ref{fig:artefacts}b) correspondant
à la coupe de l'axe X. L'image (\ref{fig:artefacts}d) correspondant à la ligne
blanche horizontal de l'image (\ref{fig:artefacts}f) où les structures linéaires
sont parallèles à la coupe et peuvent être considérées comme telles au lieu
de donner l'apparance de bruit.


\section{Les méthodes de détection de surfaces\label{sec:CadreDetection}}

Parmi les multiples méthodes de détection de frontières, quatre ont retenu notre
attention pour les appliquer sur les volumes des données. Les principes de cettes
méthodes sont présentes dans cette section. Cettes méthodes ont été modifiées
afin de pouvoir comparer leur performances en les appliquant dans les mêmes
conditions; chacune d'entre elles est en mesure de fournir les volumes des données
suivantes:

\begin{itemize}
\item un volume de données lissé
\item un volume de données gradient (module et composantes)
\item un volume de données représentant le Laplaciens.
\end{itemize}
Le volume lissé est utilisé uniquement comme référence pour vérifier l'effet
du filtrage passe-pas propre à chaque méthode. Particulièrement le compromis
entre élimination du bruit et lissage des contours.

Le volume de données du gradient sert comme indicateur de la présence de contours
importantes, tandis que le volume des données du Laplacien permet de localiser
avec précision la position des surfaces, comme l'endroit où se trouve le maximum
du gradient, donc le passage par zéro du Laplacien.


\subsection{L'opérateur basé sur les moments géométriques}

L'opérateur basé sur les moment géométriques est un opérateur non-linéaire proposé
en 2D \cite{MomentOperator2D} et généralise en 3D \cite{MomentOperator3D}\cite{Hamitouche2}.
Cet opérateur s'applique localement dans un voisinage sphérique défini par un
certain rayon. A l'intérieur de ce voisinage, les moments géométriques \( m_{ijk} \)
sont évalués jusqu'a l'ordre deux. Le volume de données étant assimile à une
fonction scalaire en 3D, \( I(x,y,z) \).


\[
m_{ijk}=\int \int \int I(x,y,z)x^{i}y^{j}z^{k}dxdydz\]


Les profils des contours à détecter sont supposés de la forme échelon. Les valeurs
des dix moments \( m_{000} \), \( m_{100} \), \( m_{010} \), \( m_{001} \),
\( m_{110} \), \( m_{101} \), \( m_{011} \), \( m_{200} \), \( m_{020} \),
\( m_{002} \), calculés dans le voisinage sont utilisés pour estimer les paramètres
propres au modèle du profil d'échelon (figure \ref{fig:EchellonSigmoide}a).
Notamment :

\begin{itemize}
\item la hauteur \( b \) de l'echelon qui représente une mesure du contraste
\item l'orientation dans l'espace, correspondant à la normale à la surface.
\end{itemize}
L'estimation pratique du moment \( m_{ijk} \), dans le voisinage d'un voxel,
se fait par correlation avec un masque precalculée, dont les coefficients de
chaque voxel correspondent à l'intégration de la fonction \( x^{i}y^{j}z^{k} \)
à l'intérieur du voxel \cite{MomentOperator3D}.


\subsubsection{les modèles de profil}

Le choix du profil d'échelon étant restrictif, des types de profils plus généraux,
notamment, les profils composés ont été étudiés et pris en compte avec les moments
géométriques\cite{MomentOtherProfiles}\cite{CompositeEdges}. 

Il est clair qu'un profil échelon est trop brusque pour représenter la réalité
physique. Même si les images ont une si haute qualité, le processus de discrétisation
fait que l'on dispose toujours de contours progressifs (le spectre du signal
doit être réduit à un support fini avant de l'échantillonner). 

Un modèle plus réaliste du profil est la fonction sigmoïde (figure \ref{fig:EchellonSigmoide}b),
mais comme il est souvent le cas quand les modèles s'approchent de la réalité,
la complexité de son calcul la rend impossible en pratique. L'observation de
cette fonction à une échelle assez réduite donne l'aspect d'un échelon, tandis
qu'à une grande échelle, elle laissera la place pour différentes regions à l'intérieur
\cite{ZuckerSigmoide}. La figure (\ref{fig:EchellonSigmoide}) illustre ce
concept. Le modèle d'échelon (figure \ref{fig:EchellonSigmoide}a) avec ses
paramètres \( (a,b,h) \) est visiblement artificiel. Le modèle sigmoïde (figure
\ref{fig:EchellonSigmoide}b) par contre est d'une complexité plus importante.
Pour simplifier son analyse, ses diverses régions peuvent être cataloguées selon
qu'elles soient dominées par un terme (C) constante, (Q-) quadratique négative,
(L) linéaire ou (Q+) quadratique positive. Dans cette optique, nous avons remplacé
l' estimation des paramètres du modèle d'échelon à partir des moments, par la
décomposition de la fonction de l'image en composantes~:\begin{figure}
{\centering \subfigure[Echelon]{\resizebox*{4cm}{4cm}{\includegraphics{data/echellon.eps}}} 
\subfigure[Sigmoide]{\resizebox*{5cm}{4cm}{\includegraphics{data/sigmoide.eps}}} \par}


\caption{\label{fig:EchellonSigmoide}Modèle de profil de niveau de gris.}
\end{figure}

\begin{itemize}
\item constantes
\item linéaires
\item quadratiques
\end{itemize}

\subsubsection{L'opérateur adapté}

La fonction \( I(x,y,z) \) représentant l'image est décomposée dans une base
vectorielle orthogonale. Les composantes \( m_{000} \), \( m_{100} \), \( m_{010} \),
\( m_{001} \) sont naturellement orthogonales entre elles. Les trois composantes
d'ordre \( 1 \) : \( \left\{ m_{100},m_{010},m_{001}\right\}  \) sont considérés
comme des estimations des composantes du vecteur gradient de la fonction \( I(x,y,z) \).
Le moment d'ordre 1, dans la direction du gradient est \( m^{'}_{1}=\sqrt{m_{100}^{2}+m_{010}^{2}+m_{001}^{2}} \).
Le moment d'ordre 2 le long de la direction du gradient \( m^{'}_{2} \), est
calculé selon les principes présentés en \cite{MomentOperator2D}\cite{MomentOperator3D}.
Ce moment n'étant pas indépendant de la composante \( m_{000} \), une orthogonalisation
simple s'avère nécessaire pour obtenir un terme \( m_{2} \) qui puisse être
interprété comme quadratique et indépendante des termes linéaire \( m_{1}' \)
et constant \( m_{000} \):


\[
m_{2}=5m^{'}_{2}-R^{2}m_{000}\]
 

\( R \) représente le rayon du voisinage considéré pour le calcul des moments.
Cette présentation de la méthode des moments permet de l'assimiler au cadre
général de détecteurs de contour décrit dans la section \ref{sec:CadreDetection},
le moment d'ordre zéro est utilisé comme volume lissé, le moment d'ordre 1 est
interprété comme module du gradient et le moment d'ordre 2 orthogonalisé, est
considéré comme Laplacien.


\subsubsection{Caractéristiques}

L'opérateur basé sur les moments a un seul paramètre à régler : le rayon \( R \)
de la sphère qui détermine le voisinage pour le calcul des moments autour de
chaque voxel. Cette méthode est adaptée de façon intrinsèque à l'anisotropie
propre des volumes de données car le voisinage sphérique est évalué dans l'espace
continu au lieu d'être mesuré en voxels. Néanmoins, les estimations fournies
par cet opérateur sont biaisées par rapport à l'orientation, ce qui a été étudié
dans \cite{MomentOperator3D}.

L'opérateur de moments s'adapte fácilement à l'anisotropie des volumes des données
car la taille du voxel est prise en compte au moment de générer les masques
de corrélation utilisées pour estimer les moments.

Une caracteristique assez intéressante de l'opérateur de moments est l'élimination
des effets de moiré ou recouvrement spectral dans l'image associée au Laplacien.
Les opérateurs appliqués par des procédures séparable ont une tendance plus
importante à générer des effets de recouvrement, conséquence normale du fait
de donner plus d'importance aux informations provenant des voisins verticaux
et horizontaux.

Il a été montré que les méthodes qui utilisent des convolutions anisotropes
ne sont pas optimales pour détecter des contours linéaires, car seulement une
partie réduite du détecteur est sensible a la surface en particulier. Il s'agit
d'un compromis entre la généralité et la sensibilité du détecteur. En revanche
les détecteurs basés sur l'utilisations de modèles de contours peuvent s'orienter
pour maximiser sa sensibilité dans la direction du contour à chaque point du
signal \cite{OptimalEdgeDetect}. L'opérateur des moments suit ce type d'approche.

Le principal inconvénient de cette méthode est son temps de calcul qui dépasse
largement celui de ses concurrents. Des méthodes mathématiques particulières
peuvent être utilisées pour accelerer le calcul des moments dans les images
\cite{MomentsFast}, mais il ne suffisent pas pour rattraper les méthodes basées
sur filtres récursifs.


\subsection{Le Laplacien d'une Gaussienne (LOG)}


\subsubsection{le modèle de la vision humaine}

La performance du système visuel humain a inspiré un certain nombre de chercheurs
pour essayer de comprendre son fonctionnement afin de l'émuler et de pouvoir
construire des algorithmes aussi efficaces.

La première de ses approches a été effectuée par Marr et Hildreth \cite{MarrHildreth}\cite{Marr}.
L'analyse de la réponse des cônes et battonets dans la rétine humaine se présente
comme une zone centrale sensible entourée d'un region d'inhibition. L'hypotèse
indique que ces structures dans la rétine étaient spécialisées dans la détection
des contours en utilisant le passage par zéro de la réponse de sa fonction de
sensibilité.

\begin{figure}
{\centering \resizebox*{8cm}{6cm}{\includegraphics{LoG/LoG1D.eps}} \par}


\caption{\label{fig:Gaussian1D}La fonction Gaussienne, sa première et seconde dérivées.}
\end{figure}

\begin{figure}
{\centering \subfigure[La fonction Gaussien]{\resizebox*{6cm}{6cm}{\includegraphics{LoG/LoG2D.eps}}} 
\subfigure[Laplacien d'une Gaussienne]{\resizebox*{6cm}{6cm}{\includegraphics{LoG/LoG2DL.eps}}} \par}

{\centering \subfigure[D\'{e}riv\'{e}e en X de la Gaussienne]{\resizebox*{6cm}{6cm}{\includegraphics{LoG/LoG2Dx.eps}}} 
\subfigure[D\'{e}riv\'{e}e en Y de la Gaussienne]{\resizebox*{6cm}{6cm}{\includegraphics{LoG/LoG2Dy.eps}}} \par}


\caption{\label{fig:Gaussian2D}La fonction Gaussienne bidimensionel}
\end{figure}

Une des caractéristiques remarquables de la rétine humaine est le fait d'utiliser
un détecteur assez étendu. Tandis que la grande majorité des méthodes de détection
de contours se limitent à un voisinage du pixel (typiquement 3x3, 5x5, 7x7 pixels,
par souci de performance). Le système de vision semble utiliser des filtres
de l'ordre de 150 éléments (cellules), ce qui est possible grâce à la haute
densité des récepteurs dans la région centrale de la rétine.


\subsubsection{Le modèle mathématique}

La fonction de sensibilité des récepteurs de la rétine fut modélisée comme le
Laplacien d'une fonction Gaussienne, figure~\ref{fig:Gaussian1D}. 


\[
G\left( x\right) =\frac{1}{\sigma \sqrt{2\pi }}\exp \left( -\frac{x^{2}}{2\sigma ^{2}}\right) \]



\[
\frac{\partial }{\partial x}G\left( x\right) =-\frac{x}{\sigma ^{3}\sqrt{2\pi }}\exp \left( -\frac{x^{2}}{2\sigma ^{2}}\right) \]



\[
\frac{\partial ^{2}}{\partial x^{2}}G\left( x\right) =\frac{\left( x^{2}-\sigma ^{2}\right) }{\sigma ^{5}\sqrt{2\pi }}\exp \left( -\frac{x^{2}}{2\sigma ^{2}}\right) \]


La fonction Gaussienne en 2D et ses dérivées sont illustrées dans la figure~\ref{fig:Gaussian2D}.
Il faut remarquer que le Laplacien de la Gaussienne est négative à l'origine.
Il est fréquent de le retrouver avec le signe inverse dans la litérature \cite{HuertasMedioni}\cite{UniquenessGaussian}. 

La mise en oeuvre de la méthode implique : 

\begin{itemize}
\item Le lissage de l'image par une convolution avec un filtre Gaussien. 
\item L'application d'un opérateur dérivatif dans chacune des directions des axes
de coordonnées pour obtenir le gradient. 
\item Une deuxième application des opérateurs dérivatifs pour d'obtenir le Laplacien
de l'image. 
\end{itemize}
Il a été prouvé que cette procédure est équivalente à appliquer des convolutions
avec des dérivées de la fonction Gaussienne \cite{ZeroCrossRepresentation}:


\[
\frac{\partial }{\partial x}\left( G\star I\right) =\frac{\partial G}{\partial x}\star I=G\star \frac{\partial }{\partial x}I\]
 


\[
\nabla \left( G\star I\right) =\nabla G\star I=G\star \nabla I\]


Il est plus intéressant de générer d'abord les filtres équivalents à la fonction
Gaussienne et ses dérivées pour les convoluer ensuite avec l'image.


\subsubsection{L'espace échelle}

L'approche de Marr et Hildreth a été à l'origine de l'étude des approches multi-échelle.
Comme il a été signalé dans la section~\ref{sec:multi-echelle}, la généralité
du concept de contour oblige à chercher des transitions des niveaux de gris
à plusieurs échelles, sauf bien évidemment, dans les cas où une information
a priori est disponible sur le contenu de l'image.

La fonction Gaussienne s'avère être la seule à satisfaire les conditions nécessaires
pour une approche multi-échelles, quand elles est conçue sur des fonctions continues
\cite{UniquenessGaussian}. Néanmoins, le fait de devoir reproduire le processus
de détection à chaque échelle implique un temps de calcul prohibitif. Des approches
dans le domaine des ondelettes se révèlent plus efficaces, car d'une part, elles
échantillonnent l'espace à des valeurs discrètes (puissances de deux) et d'autre
part produisent des informations décorrelées a chaque échelle (orthogonalité).

Un processus d'interprétation de l'information présente s'avère nécessaire dans
l'espace échelle, car l'apparition de nombreux passages par zéro gène l'identification
des contours importants. La proximité des surfaces introduit aussi des passages
par zéro qui ne correspondent pas au maximum d'un gradient \cite{AuthenticatinZeroCrossing}\cite{ScaleSpaceStability}.


\subsubsection{La performance}

Par souci de temps de calcul, certains travaux ont porté sur l'approximation
du Laplacien de la Gaussienne (LoG) par la différence de deux Gaussiennes (DoG)
\cite{MarrHildreth}\cite{HuertasMedioni}, ce qui réduit le nombre d'opérations
à effectuer, mais en pratique, le filtre est de toute manière tronqué, car le
calcul doit être effectué sur un support fini. Cette troncature est habituellement
de l'ordre de \( 3\sigma  \) ou \( 4\sigma  \) de l'origine.

Les difficultés de performance dans l'application des filtres Gaussiens peuvent
être surmontées grâce à l'utilisation de filtres récursifs qui approchent le
profil Gaussien. Dans notre cas, la méthode implantée est celle proposée par
Deriche avec un filtre récursif d'ordre 4 \cite{GaussienRecursive}. 

La précision de la localisation des surfaces est biaisée par la forme des contours.
La convexité ou concavité de la surface déplace le passage par zéro du Laplacien
par rapport à la vrai position du contour \cite{ScaleSpaceConvexShapes}. Il
est raisonnable de s'attendre à des biais similaires pour les autres détecteurs
de contours, d'autant plus forts que la taille du détecteur est importante.

Pour faire face à l'anisotropie du volume de données, les valeurs de \( \sigma  \)
sont pondérés par la taille du voxel en chaque direction. De cette manière une
valeur \( \sigma  \) au sens physique est spécifié par l'utilisateur, mais
trois valeurs \( (\sigma _{x},\sigma _{y},\sigma _{z}) \) au sens discret,
sont utilisées au moment d'appliquer le filtre récursif dans chaque direction.


\subsection{L'opérateur de Canny et Deriche}


\subsubsection{Le concept d'optimisation}

L'opérateur de Canny a été développé comme la solution d'un problème d'optimisation
avec contraintes \cite{Canny}. Cet opérateur fournit un compromis optimal entre
les critères suivants :

\begin{itemize}
\item Localisation
\item Détection
\item Unicite de la réponse
\end{itemize}
Il faut remarquer que le détecteur est optimisé sous l'hypotèse que le bruit
présent dans la signal est additif, blanc, gaussian et centré. Ce qui n'est
malheureusement pas le cas dans les volumes des données provenant de Scanner
X ou d'IRM. L'opérateur développé initialement par Canny est un filtre à Réponse
impulsionnelle finie (RIF), une version utilisant un filtre à réponse impulsionnelle
infinie (avec une implantation récursive) a été développé par Deriche. C'est
cette version que nous avons implantée et comparée avec les autres détecteurs
de contours \cite{DericheRecursive}.


\subsubsection{Le modèle mathématique}

L'opérateur optimal suivant ces critères utilise une fonction de lissage définie
par:


\[
S(x)=k_{1}\left( \alpha \left| x\right| +1\right) e^{\left( -\alpha \left| x\right| \right) }\]


avec :


\[
k_{1}=\frac{\left( 1-e^{-\alpha }\right) ^{2}}{\left( 1+2\alpha e^{-\alpha }-e^{-2\alpha }\right) }\]


Le paramètre \( \alpha  \) permet de régler le niveau de lissage à appliquer
sur l'image, plus il est faible, plus le lissage est important. Le filtre de
dérivation correspond à la fonction :


\[
D(x)=k_{2}xe^{-\alpha \left| x\right| }\]


avec :


\[
k_{2}=-\frac{\left( 1-e^{-\alpha }\right) ^{2}}{e^{-\alpha }}\]


Le filtre Laplacien est :


\[
L(x)=\left( 1-k_{3}\alpha \left| x\right| \right) e^{-\alpha \left| x\right| }\]


avec :


\[
k_{3}=\frac{\left( 1-e^{-2\alpha }\right) }{2\alpha e^{-\alpha }}\]



\subsubsection{Mise en oeuvre}

La mise en oeuvre récursive de cet opérateur permet d'augmenter ses performances
de façon très importante \cite{DericheRecursive}. Le filtre récursif équivalent
est d'ordre 2, ce qui donne à la méthode les temps de calcul les plus faibles
par rapport aux autres méthodes.

En 2D et 3D le filtre est implanté implanté de façon séparable en réutilisant
le filtre 1D : \( F_{2D}(x,y)=F_{1D}(x)F_{1D}(y) \) et \( F_{3D}(x,y)=F_{1D}(x)F_{1D}(y)F_{1D(z)} \).
Une approche plus formelle aurait impliquée la reproduction du processus d'optimisation
posé en 2D et 3D pour obtenir des filtres de symétrie circulaire et sphérique
respectivement. Ce choix de la séparabilité introduit des anisotropies dans
le comportement de la sensibilité du filtre, notamment réduisant sa fiabilité
dans les orientations écartés des axes de coordonnées \cite{INRIA2}\cite{INRIA3}.

Nous avons pris en compte l'anisotropie du volume de données en appliquant une
pondération à la valeur de \( \alpha  \) par la taille du voxel. L'utilisateur
spécifie une valeur de \( \alpha  \) au sens physique (en millimètres), qui
est ensuite utilisée pour créer trois valeurs \( (\alpha _{x},\alpha _{y},\alpha _{z}) \)
correspondant aux filtres récursifs dans chaque axe de coordonnées.

Il faut remarquer que la \emph{séparabilité} en général est une grave erreur
quand-il s'agit de transposer les résultats obtenus en 1D vers 2D ou 3D. Il
s'avère être un choix de la facilité, qui permet d'obtenir des résultats rapidement;
mais à long terme conduit à des erreurs de conception et d'interprétation. Des
approches ont été proposées pour construire détecteurs 2D à partir des détecteurs
1D sans le concept de separabilité, tout en optimisant la réponse directionelle
du détecteur \cite{DirectionalFiltering}.

Seulement dans le cas de la Gaussienne, la séparabilité conduit à un résultat
similaire, car le produit de Gaussiennes implique la somme des carrés de variables.
Ce même problème se retrouvera également, au moment d'aborder la définition
de la topologie dans les espaces discrets et lors de la parametrisation des
surfaces pour la modélisation et visualisation des formes. 

Ce qui semble une astuce, devient finalement une piège. Tout simplement parce
que chaque fois que l'on passe d'un espace de dimension \( n \) vers une autre
de dimension \( (n+1) \), la description cohérente de l'espace nécessite \( (n+1) \)
directions additionnels au lieu d'une seule. 


\subsection{L'opérateur de Shen et Castan}


\subsubsection{Le principe de conception}

L'opérateur de Shen et Castan peut être considéré comme une variante de l'opérateur
de Canny et Deriche. Ce filtre linéaire optimal est basé sur le modèle d'une
frontière échelon avec un bruit blanc additionnel.

Un critère plus exigent dans la précision de la localisation de la surface a
amené à utiliser un filtre exponentiel qui se met en oeuvre aussi de façon récursive,
donc efficace \cite{CastanZaoShen}\cite{ShenCastan}.


\subsubsection{Le modèle mathématique}

L'opérateur applique un lissage avec une fonction exponentielle définie par~:


\[
S(x)=k_{1}e^{-\alpha \left| x\right| }\]


avec :


\[
k_{1}=\frac{1-e^{-\alpha }}{1+e^{-\alpha }}\]


La détection de la surface est effectuée par le filtre dérivatif :


\[
D(x)=-sign(x)\frac{\left( 1-e^{-\alpha }\right) }{e^{-\alpha }}e^{-\alpha \left| x\right| }\]


Le Laplacien est défini par :


\[
L(x)=k_{1}e^{-\alpha \left| x\right| }-1\]



\subsubsection{La mise en oeuvre}

Les convolutions avec les réponses impulsionnelles de ce détecteur se mettent
en oeuvre en utilisant de filtres récursifs d'ordre 1. La mise en oeuvre en
2D et 3D se fait par l'application d'un produit tensoriel, qui rend des filtres
séparables.

Cet opérateur génère des Laplaciens de haute définition, dont la localisation
de la surface est très nette. Son inconvénient est la forte tendance à surestimer
les directions des axes de coordonnées, car le filtre réalisé n'est pas anisotrope.
Il se comporte très bien en détection de surfaces dans des images des objets
\emph{faits par l'homme} puisque les surfaces les plus importantes se trouvent
dans les directions verticale et horizontal, des images des bâtiments ou des
espaces mueblés par exemple.

Le réglage du paramètre \( \alpha  \) permet de contrôler la sensibilité du
détecteur à plusieurs échelles différentes. Notamment, il est relié au facteur
de lissage, donc, à la réduction du bruit \cite{Deriche}. Ce paramètre est
pondéré par la taille du voxel afin de compenser l'anisotropie du volume des
données. L'utilisateur choisit une valeur de \( \alpha  \) avec un sens physique
en millimètres, qui est convertie en trois valeurs \( (\alpha _{x},\alpha _{y},\alpha _{z}) \)
pour le filtre récursif à appliquer dans chacune des directions du système de
coordonnées.


\section{La performance des méthodes de détection de contours}

Le but du processus de extraction de contours est la construction d'une représentation
géométrique du contour à partir de l'information fournie par le processus de
détection. L'extraction de surface peut être décomposée en trois étapes: 

\begin{enumerate}
\item Détermination des couples de voxels entre lesquels passe le contour. 
\item Estimation de la position de passage du contour avec précision sous-voxel.
\item Construction d'un triangulation qui reconstitue la connexité topologique entre
les points du contour.
\end{enumerate}
Le processus d'extraction de surface que nous avons développée ici, est inspiré
de~: 

\begin{itemize}
\item La méthode classique de ``\emph{marching cubes''} \cite{MarchingCubes} en
ce qui concerne la connexité topologique entre points appartenant à la surface. 
\item L'estimation de position de points de la surface avec précision sous-voxel proposé
dans les méthodes du filtrage LoG \cite{HuertasMedioni}\cite{AuthenticatinZeroCrossing}\cite{ZuckerSigmoide}
\end{itemize}
Nous avons adapté cettes méthodes à la grille BCC \cite{ICIP96}. Dans la grille
BCC, les voxels sont définis comme étant les polyèdres correspondants à la figure
de Voronoï de la grille. Ce type de voxel a l'avantage de permettre la définition
d'une topologie dans laquelle deux voxels sont voisins s'ils partagent une facette.
Un voxel a donc, quatorze voisins, dont huit a distance \( \sqrt{3} \) et six
a distance \( 2 \) \cite{Ibanez96}\cite{HermanSummerSchool}. 


\subsection{Détection de la surface}

Pour déterminer la position de la surface il ne suffit pas d'appliquer une des
méthodes de détection. Il faut, additionellement, analyser les volumes de données
fournis par ces méthodes pour déterminer le lieu de passage de la surface entre
les voxels. Parmi ces volumes des données nous avons une estimation du Laplacien
et du module du gradient, évalués dans tous les voxels de l'image.

Le module du gradient est associée à l'importance du changement de niveau de
gris dans l'image. Le passage par zéro du Laplacien est associé au maximum d'intensité
du gradient. Typiquement ce passage par zéro se produit entre deux voxels tels
que un a un valeur positive du Laplacien et l'autre un valeur négative. Il est
donc naturel de placer les points de la surface entre les voxels dont le Laplacien
a un signe contraire. Le critère de passage par zéro du Laplacien permet de
garantir la cohérence topologique puisque il partitione le volume des données
en deux populations, une avec Laplacien positif et l'autre avec Laplacien négatif. 

Il est, néanmoins, possible de trouver des passages par zéro dans toutes les
régions du volume de données. Il faut donc se limiter à ceux correspondant au
valeurs importants du module du gradient. Nous considérons seulement les couples
de voxels tels que: 

\begin{itemize}
\item Le module du gradient dans les deux voxels est supérieur à un seuil \( S_{g} \).
\item Le signe du Laplacien est différent dans chaque voxel.
\end{itemize}

\subsection{Estimation de la position sous-voxel}

Une fois que une couple de voxels \( a \) et \( b \) a été trouve, tels que
ses gradients \( G(a) \) et \( G(b) \) soient supérieures au seuil \( S_{g} \)
et ses Laplaciens \( L(a) \) et \( L(b) \) soient de signe contraire, nous
plaçons un point de la surface le long de la ligne qui relie les deux voxels.
La position exacte dans la ligne est estimée par simple interpolation linéaire
entre les valeurs du Laplacien, sachant que le point doit être placé dans l'isosurface
de valeur \( 0 \) du Laplacien. 

Pour le cas de deux voxels \( a \) et \( b \) voisins, placés en positions
\( \overrightarrow{V(a)} \) et \( \overrightarrow{V(b)} \) respectivement,
avec des valeurs de Laplacien \( L(a)\geq 0 \) et \( L(b)<0 \), la position
\( \overrightarrow{P} \) du point de la surface est estimée par:


\[
\overrightarrow{P}=\frac{L(a)\overrightarrow{V(b)}-L(b)\overrightarrow{V(a)}}{L(a)-L(b)}\]



\subsection{Connexion des voisins}

Maintenant que les points de la surface on été détectés et ses position estimées,
il est nécessaire de construire un triangulation entre eux pour représenter
l'estructure topologique de la surface.

\begin{figure}
{\centering \includegraphics{data/star.eps} \par}


\caption{\label{fig:Star}Codage des relations de voisinage dans la surface extraite.}
\end{figure}


\subsubsection{La représentation des voisinage}

Comme représentation des connexions entre les points de la surfaces nous avons
retenu la notion des \emph{étoiles} de la théorie topologique des graphes \cite{GraphTheory}.
Cette représentation simplifie les processus topologiques et augmente la performance
de son exécution. Actions tels que l'insertion et l'enlèvement des noeuds, la
vérification de genus de la surface et l'évaluation de la courbure discrète
sont réalises facilement dans cette représentation. Contrairement à ce qui arrive
avec une représentation basé sur la description des polygones de la surface,
comme celle qui a été développée dans la méthode de \emph{marching cubes} et
en générale dans les méthodes qui sont concernés uniquement par la visualisation
et non par la manipulation et l'analyse des surfaces. 

La figure \ref{fig:Star} illustre le mécanisme de codage des relations de voisinage
dans la surface. Le noeud numéro \( 15 \) a comme voisins la suite de noeuds
\{45, 67, 58, 23, 8, 74, 35 \}. Cette suite est ordonnée dans le sens anti-horaire
quand elle est vue depuis l'extérieur de la surface. Chaque noeud possède une
liste des voisins. Additionellement, un drapeau est utilisé dans chaque noeud
pour indiquer s'il est un point de frontière ou pas.


\subsubsection{La détermination des voisins}

\begin{figure}
{\centering \includegraphics{data/association.eps} \par}


\caption{\label{fig:AssociationSurfaceKcomplex} Association de voisinage dans la grille
hexagonale. A gauche: structure topologique des pixels. A droite: contour détecté
entre points de la grille.}
\end{figure}

Pour réaliser les connexion entre les points de la surface, une association
est faite entre les notions de grille d'échantillonnage et celles d'estructure
polygonale. La figure \ref{fig:AssociationSurfaceKcomplex} illustre ces associations
pour le cas d'une grille hexagonale. A gauche on trouve trois pixels hexagonaux
\( A \), \( B \) et \( C \). Dans la grille hexagonale deux pixels sont voisins
s'ils partagent une arête. Dans le cas de la figure, les pixels \( A \) et
\( B \) sont voisins car ils partagent l'arête \( F1 \), de façon analogue
les pixels \( A \) et \( C \) sont voisins car ils partagent l'arête \( F2 \). 

A droite dans la figure \ref{fig:AssociationSurfaceKcomplex} on trouve les
points \( A \), \( B \) et \( C \) de la grille hexagonale \emph{associés}
aux pixels de gauche. Les signes du Laplacien sont indiqués à l'intérieur des
points de la grille. Notre méthode placera un point de contour dans la ligne
qui relie deux pixels avec Laplacien de signe contraire. Il y en a, donc un
point de contour \( P1 \) entre les points de la grille \( A \) et \( B \),
ainsi que un point de contour \( P2 \) entre les points de la grille \( A \)
et \( C \). Le point de contour \( P1 \) est associé à la facette \( F1 \),
tandis que le point de contour \( P2 \) est associé à la facette \( F2 \).
Les deux points de contour seront connexes dans le contour si et seulement si
les deux facettes \( F1 \) et \( F2 \) qui leur sont associées partagent un
sommet \( V \). Dans ce cas, le sommet \( V \) est associé à la ligne \( L \)
qui connecte les deux point de contour \( P1 \) et \( P2 \).

\begin{figure}
{\centering \includegraphics{data/associatonBCC.eps} \par}


\caption{\label{fig:ConstructionTriangulationEnBCC}Relations d'association dans la
grille BCC entre les éléments de la grille et ceux de la structure polyèdrale
des voxels.}
\end{figure}

Nous avons appliqué ce concept à la grille BCC et la structure polyèdrale composée
des figures de Voronoï avec ses facettes, arêtes et sommets. La figure \ref{fig:ConstructionTriangulationEnBCC}
illustre les association correspondantes. Les points \( A \), \( B \) et \( C \)
de la grille (a droite) sont associés aux voxels (polyèdre de Voronoï) \( A \),
\( B \) et \( C \) (a gauche). Un point de surface \( P1 \) est placé dans
la ligne que relie deux points \( B \) et \( C \), ainsi que un point de surface
\( P2 \) est placé dans la ligne entre \( A \) en \( B \). Les points \( P1 \)
et \( P2 \) de la surface sont associés aux facettes \( F1 \) et \( F2 \)
de la structure polyherale. Finalement, la ligne \( L \) reliant les points
de surface \( P1 \) et \( P2 \), est associée à l'arete \( E \) partagé par
les deux voxels facettes \( F1 \) et \( F2 \).

Les possibles relations de voisinage entre points de la surface correspondent
aux possibles configurations géométriques des arêtes et facettes dans les polyèdres.
Cette à dire, dans la surface \( S \) il y aura un ligne qui relie deux points
de surfaces, si, dans la structure géométrique formée par le polyèdres existe
une arête qui connecte les deux facettes.

Les desavantages de la surface extraite avec cet approche sont:

\begin{itemize}
\item Le grand nombre de triangles qu'il génère 
\item L'apparition abondante des triangles allongés
\end{itemize}
Défauts qui sont partagé avec la méthode de marching cubes. 


\section{Comparaison de performance des méthodes de détection de contours }

La qualité du processus de détection doit être évaluée en fonction de sa contribution
au bon déroulement de l'extraction. Il est courant de juger la performance des
méthodes de détection par des critères visuels \cite{ComparingMethods}, mais,
ce type de comparaison est rarement juste car il est difficile, sinon impossible,
d'établir visuellement la cohérence topologique au niveau pixel. Néanmoins,
comme il est le cas dans la plupart d'activités liées au traitement de l'image,
la validité d'une méthode dépends de l'application envisagée. 

La comparaison objective des performances des différents méthodes de détection
de contour implique le test des critères suivants:

\begin{itemize}
\item Précision de la localisation
\item Précision de l'orientation de la normale
\item Sensibilité au bruit
\item Temps de calcul
\end{itemize}
Pour évaluer ces différents critères, un volume de données synthétique contenant
une sphère a été utilisé comme patron. Les différentes méthodes de détection
ont été appliquées sur cette même volume, est la surface extraite a été analysée.


\subsection{Construction du volume de données test}

Le rayon de la sphère a été choisi de 50 voxels de façon à pouvoir considérer
la région concernée par le voisinage du filtrage comme approximativement plane.
Cette taille représente bien un cas réel d'acquisition d'image d'une articulation
à une résolution proche du millimètre. Une taille totale de 128x128x128 (puissance
de 2) a été retenue pour pouvoir appliquer directement l'algorithme de transformation
de Fourier rapide (FFT) \cite{FFTalgo}. 


\subsubsection{La fonction et son spectre}

La fonction continue de la sphère est définie par :


\[
f(\overrightarrow{x})=\left\{ \begin{array}{lcr}
A & si & \left\Vert \overrightarrow{x}\right\Vert <R\\
0 & si & \left\Vert \overrightarrow{x}\right\Vert \geq R
\end{array}\right. \]


Le spectre de ce signal est donné par la transformation de Fourier :


\[
F(\overrightarrow{w})=\int \int \int f(\overrightarrow{x})e^{\left( -2\pi i\left( \overrightarrow{w}\cdot \overrightarrow{x}\right) \right) }d\overrightarrow{x}\]
 

En prenant en compte la symétrie sphérique de la fonction, telle que :


\[
\overrightarrow{w}\cdot \overrightarrow{x}=\left\Vert \overrightarrow{w}\right\Vert \left\Vert \overrightarrow{x}\right\Vert \cos (\kappa )\]


où \( \kappa  \) est l'angle forme entre le vecteur de position \( \overrightarrow{x} \)
et le vecteur d'orientation de la fréquence \( \overrightarrow{w} \). L'intégrale
pour une valeur particulière de \( \left\Vert \overrightarrow{w}\right\Vert  \)
se réalise sur les domaines de \( \left\Vert \overrightarrow{x}\right\Vert  \)
et de \( \kappa  \), pour devenir :


\[
F(\omega )=2\pi A\int ^{\pi }_{0}\int ^{R}_{0}e^{\left( -2\pi i(\omega \cdot r\cos (\kappa ))\right) }r^{2}\sin \kappa d\kappa dr\]


où \( r=\left\Vert \overrightarrow{x}\right\Vert  \) et \( \omega =\left\Vert \overrightarrow{w}\right\Vert  \).
L'intégration sur \( \kappa  \) conduit à :


\[
F(\omega )=2\pi A\int ^{R}_{0}\frac{r}{2\omega \pi }\sin \left( 2r\omega \pi \right) dr\]


et l'intégration sur \( r \) produit finalement :


\begin{equation}
\label{eqn:TransfFourierSphere}
F(\omega )=\frac{A}{2\omega ^{3}\pi ^{2}}\left[ \sin (2R\omega \pi )-2R\omega \pi \cos (2R\omega \pi )\right] 
\end{equation}


Cette analyse a été effectuée à l'aide du logicielle de mathématique symbolique
MuPAD \cite{MuPAD}. La valeur de la fonction pour \( \omega =0 \) doit être
évaluée en tant que la limite :


\[
\lim _{\omega \rightarrow 0}F(\omega )=\frac{4\pi AR^{3}}{3}\]


La figure (\ref{fig:FTSphere}) montre le profil radiale de cette fonction.
L'échelle horizontale est présentée en multiples de \( \frac{1}{R} \). Ce spectre
est bien évidemment de support infini. Il doit être limité pour satisfaire les
critères de Shannon \cite{Rosenfeld}\cite{DungeonMersereau}. 

\begin{figure}
{\centering \resizebox*{6cm}{4cm}{\includegraphics{data/FTSphere.eps}} \par}


\caption{\label{fig:FTSphere} Profil radiale de la transformation de Fourier de un
sphère solide}
\end{figure}


\subsubsection{Limitation du spectre}

La réduction du support du spectre d'un signal consiste, traditionnellement
à multiplier son spectre par une fonction échelon de symétrie sphérique. La
conséquence de cette multiplication est de faire subir au signal d'entrée une
convolution avec la transformée de Fourier inverse de la fonction choisi pour
tronquer le spectre. 

Nous profitons ici, du fait d'avoir établie déjà le couple de fonctions \( f(\overrightarrow{x})\rightleftharpoons F(\overrightarrow{w}) \)
comme reliées par une transformation de Fourier. La fonction de fenêtrage (ou
réponse fréquentielle) \( H\left( \overrightarrow{w}\right)  \) étant une sphère
de rayon \( \Omega  \) dans le domaine de la fréquence, la réponse impulsionelle
\( h\left( r\right)  \) dans le espace de la signal est :


\[
h(r)=\frac{1}{2r^{3}\pi ^{2}}\left[ \sin (2\Omega r\pi )-2\Omega r\pi \cos (2\Omega r\pi )\right] \]


En conclusion, pour remettre le signal d'entrée dans les conditions exigées
par le critère de Shannon il faut convoluer la fonction sphérique \( f(\overrightarrow{x}) \)
par la fonction \( h\left( r\right)  \) avant d'effectuer la discrétisation
(d'échantillonnage).

La valeur de \( \Omega  \) détermine la fréquence maximale que nous voulons
retenir du signal original. L'observation de la figure (\ref{fig:FTSphere})
conduit à conclure qu'une fréquence de \( \Omega =3/R \) semblerait suffisante.
La fonction de convolution dans ce cas serait :


\[
h(r)=\frac{1}{2r^{3}\pi ^{2}}\left[ \sin (6\pi r/R)-(6\pi r/R)\cos (6\pi r/R)\right] \]


Sachant que le spectre de cette nouvelle fonction est limité à la fréquence
\( \Omega  \), le pas d'échantillonnage \( \delta  \) doit satisfaire \( \delta \leq \frac{1}{2\Omega } \)
ce qui implique, pour notre choix de truncature que : \( \delta \leq \frac{R}{6} \).
Néanmoins, notre choix de construire une sphère de rayon 50 voxels dépasse largement
la restriction de \( \Omega =3/R \). Nous pouvons donc inverser les considérations
pour chercher à partir du pas d'échantillonage \( \delta \leq \frac{R}{50} \)
quelle est la fréquence maximale à retenir et en conséquence quel serait la
fonction de convolution \( h\left( r\right)  \). Le calcul conduit immédiatement
à une valeur de \( \Omega =25/R \) et une fonction de convolution :


\[
h(r)=\frac{1}{2r^{3}\pi ^{2}}\left[ \sin (50\pi r/R)-(50\pi r/R)\cos (50\pi r/R)\right] \]


La valeur de \( h \) pour \( r=0 \) est:


\[
h(0)=\frac{62500\pi }{3R^{3}}\]


Notre sphère \( f(\overrightarrow{x}) \) doit être convoluée avec la réponse
impulsionelle \( h(\overrightarrow{x}) \), pour obtenir une fonction de test
\( f_{S}(\overrightarrow{x}) \) avec spectre à bande limité, suitable pour
l'échantillonnage :


\begin{equation}
\label{eqn:ConvolutionSphereSphere}
f_{s}(\overrightarrow{x})=\int h(\overrightarrow{y})f(\overrightarrow{x}-\overrightarrow{y})d\overrightarrow{y}
\end{equation}


Dans le procès de détection de surfaces, nous sommes interesés à la forme de
la fonction \( f_{s}(r) \) pour de valeurs de \( r \) autour de \( R \).
Cette à dire, sachant que la surface de notre objet synthétique est une sphère
de rayon \( R \), nous devons nous concentrer sur la région de transition de
la fonction \( f_{s}(r) \), \( r\rightarrow R \) car elle corresponds au voisinage
de la surface à détecter et extraire. 


\subsubsection{Le profil de la frontière }

Pour caracteriser le profile théorique du niveau de gris dans le voisinage de
la surface, la convolution entre les fonctions \( f(\overrightarrow{x}) \)
et \( h(\overrightarrow{x}) \), doit être calculé selon l'équation \ref{eqn:ConvolutionSphereSphere}.
En prenant en compte la symétrie sphérique de \( h(\overrightarrow{x}) \) et
le fait que \( f(\overrightarrow{x}) \) est équivalente à une fonction indicatrice,
l'intégrale peut être réduite à une intégrale linéaire. 

La figure \ref{fig:convolution} illustré les relations géométriques de cette
intégrale, le cercle a gauche représente la fonction \( h \) tandis que le
cercle a droite représente le support de la fonction \( f \). La valeur de
\( f(r) \) est constante à l'intérieur de la sphère de rayon \( R \) et nulle
ailleurs. Pour évaluer La fonction \( f_{s} \) dans le point \( C_{1} \),
les valeurs de \( h(\overrightarrow{x}) \) doivent être intégrées à l'intérieur
de la sphère de rayon \( R \) centrée au point \( C_{2} \). La symétrie sphérique
de \( h \) implique que tous les points dans le casquette sphérique \( C_{s} \)
ont la même valeur que le point \( P \). L'intégral se réduit donc, a la somme
des valeurs de \( h(a) \) ponderées par le volume différentielle du casquette
sphérique \( C_{s} \). Le casquette \( C_{s} \) est composée de tous les points
situées à distance \( r\in [a,a+dr] \), du point \( C_{1} \), étant à l'intérieur
de la sphère de \( f \).

\begin{figure}
{\centering \includegraphics{data/convolution.eps} \par}


\caption{\label{fig:convolution}Relations géométriques de la convolution de l'image
synthétique et la réponse impulsionnelle.}
\end{figure}

La surface du casquette sphérique d'angle interne \( A \) sur une sphère de
rayon \( a \) est:


\[
2\pi a^{2}\left( 1-\cos A\right) \]


La relation entre les angles \( A \) et \( B \) est :


\[
D=a\cos A+b\cos B\]


Le volume du casquette sphérique dans la figure \ref{fig:convolution} est donné
par : 


\[
dV=2\pi \left( a^{2}-a\left( D-R\cos B\right) \right) da\]



\[
da=\frac{DR}{a}\sin BdB\]



\[
dV=2\pi DR\left( a-\left( D-R\cos B\right) \right) \sin BdB\]



\[
a=\left( D^{2}-2DR\cos B+R^{2}\right) ^{\frac{1}{2}}\]


La convolution devient :


\[
f_{s}\left( D\right) =2\pi DR\int ^{\pi }_{0}h(a)\left[ \left( a-\left( D-R\cos B\right) \right) \sin B\right] dB\]


L'évaluation de \( h \) pour des valeurs de \( B \), entraîne l'apparition
des fonctions de type \( cos(cos(x)) \) qui ne sont pas solubles par des méthodes
analytiques. Une évaluation par de méthodes numériques s'impose. La figure (\ref{fig:ReponseIndicielle})
montre le résultat d'une évaluation de \( f_{s} \) par une méthode numérique
d'intégration. L'échelle horizontal est mesuré en échantillons (voxels). 

\begin{figure}
{\centering \resizebox*{6cm}{4cm}{\includegraphics{data/prof_contour.eps}} \par}


\caption{\label{fig:ReponseIndicielle}Réponse indicielle d'une fenêtre sphérique.}
\end{figure}

La fonction présente les ondulations qui sont typiques des fonctions qui ont
un spectre avec des transitions rapides. Ces ondulations ne sont pas convenables
dans le contexte de la détection de surfaces. Elles peuvent être évitées en
utilisant une fonction de troncature à transition progressive comme celle de
Hamming ou celle de Hannig \cite{DungeonMersereau}. Nous avons retenu parmi
elles, le choix d'une fonction Gaussienne. 


\subsubsection{Filtrage par une fonction Gaussienne }

\begin{figure}
{\centering \resizebox*{8cm}{6cm}{\includegraphics{data/FTSphereGauss.eps}} \par}


\caption{\label{fig:tfSphere_Gaussian}Spectre de la fonction sphérique avec une Gaussienne
de taille adapté. L'échelle horizontale est exprimée en multiples de 1/R.}
\end{figure}

Une bonne alternative est l'utilisation d'une Gaussienne comme fonction de transfert.
L'atténuation rapide du spectre \( F\left( \overrightarrow{w}\right)  \) permet
de considérer la Gaussienne comme suffisamment plate dans la région où le contenu
énergétique du spectre est important. La figure \ref{fig:tfSphere_Gaussian}
montre le choix d'une fonction Gaussienne de taille adéquate pour filtrer la
fonction sphérique \( f\left( \overrightarrow{x}\right)  \). La valeur de \( \sigma  \)
doit être choisie pour atténuer les fréquences supérieures à \( 50/R \). Dans
le cas de la figure, la valeur retenue est \( \sigma =0.1/R \). Les perturbations
de la région centrale du spectre peuvent être évaluées en prenant la différence
:


\[
F\left( \overrightarrow{w}\right) -F\left( \overrightarrow{w}\right) \cdot G\left( \overrightarrow{w}\right) \]


La figure \ref{fig:DiffSpectreFiltre} illustre les résultats de cette évaluation
pour la valeur de \( \sigma  \) retenue .

\begin{figure}
{\centering \resizebox*{8cm}{6cm}{\includegraphics{data/FTSphereGaussDiff.eps}} \par}


\caption{\label{fig:DiffSpectreFiltre}Changement subi par le spectre de la fonction
sphérique après le filtrage Gaussien.}
\end{figure}

\begin{figure}
{\centering \resizebox*{8cm}{6cm}{\includegraphics{data/FTSphereBord.eps}} \par}


\caption{\label{fig:SphereGaussianBord}Réponse impulsionelle du filtre Gaussian et
profil de surface résultant. Échelle horizontale en voxels.}
\end{figure}

La réponse impulsionnelle correspondant au filtre Gaussien choisi, ainsi que
le profil de surface qui apparaît après le filtrage sont illustrés dans la figure
\ref{fig:SphereGaussianBord}. Ce profil étant tout simplement la fonction :


\begin{equation}
\label{eqn:ProfilSphereGaussienne}
p(x)=\frac{1}{2}\left( erf\left( \frac{x}{\sigma \sqrt{2}}\right) +1\right) 
\end{equation}


Soumis à l'approximation de considérer la fonction sphérique \( f\left( \overrightarrow{x}\right)  \)
comme un front plat par rapport a la taille de la fonction de réponse impulsionelle.
Il est important de remarquer que pour des objets de rayon inférieur le profil
de contour présentera un transition plus forte. La fonction d'équation \ref{eqn:ProfilSphereGaussienne}
est utilisée ici pour synthétiser un sphère de rayon 50 voxels.


\subsection{Tests de détection et extraction de surfaces}

Pour chacune des méthodes de détection, des tests ont été effectués en variant
les valeurs du paramètre de filtrage. Les critères retenus comme pertinents
pour la comparaison sont les suivants : 

\begin{itemize}
\item Le décalage du centre de la sphère 
\item L'estimation du rayon moyen
\item L'écart type du rayon 
\item L'erreur quadratique entre le rayon et sa valeur théorique de 50 voxels
\item L'erreur moyenne du rayon (permettant de déterminer si les points sont détectes
du coté externe ou interne de la surface théorique)
\item L'écart type de l'erreur du rayon (mesure de la rugosité de la surface ou des
déformations globales comme l'excentricité par exemple)
\item Décalage du centre, il représente des éventuelles réponses anisotropiques (par
rapport à la direction) qu'on peut s'attendre des méthodes de filtrage récursives.
\item Le nombre de points et le nombre de triangles sont plutôt indicatifs de la méthode
de extraction de surface.
\item La correlation entre l'estimation de la normale et son valeur théorique.
\end{itemize}
Toutes les valeurs reportées sont mesurées en millimètres pour les dimensions
et en degrés pour les angles.


\subsubsection{Détecteur Gaussien}

Le filtre Gaussien a été appliqué pour diverses valeurs de \( \sigma  \) à
la sphère de test. Les principales caractéristiques de la surface extraite sont
présentées dans le tableau \ref{tab:GaussianTests}. Les valeurs de \( \sigma <0.3 \)
donnent en sortie un module du gradient qui est une copie de l'image, puisque
la discrétisation, fait que ce fitrage soit équivalent à une convolution par
une impulsion Dirac. Pour la valeur de \( \sigma =0.40 \) le résultat du module
du gradient est satisfaisant à l'oeil, mais la distribution des niveaux de gris
rend impossible une segmentation complète puisque le filtre produit un niveau
de gris de valeur non nul dans les régions uniformes. Les valeurs affichés dans
le tableau correspondent donc à une surface incomplète. 

Les valeurs du gradient dépendent des valeurs de \( \sigma  \). Pour illustrer
cette dépendance, la valeur maximale du gradient est présentée pour chaque \( \sigma  \)
dans le tableau \ref{tab:GaussianTests}. Cette relation est la conséquence
de la généralité de la notion de surface en tant que \emph{transition} de niveau
de gris dans une certaine distance. 

La figure \ref{fig:EstimationRayonGauss} illustre les relations entre la valeur
\( \sigma  \) et l'erreur d'estimation du rayon. La ligne centrale représente
la valeur moyenne du rayon tandis que les barres d'erreur représentent les valeurs
minimale et maximale. Le rayon est toujours surestimé. Les meilleurs résultats
ont été obtenus pour les valeurs de \( \sigma \approx 0.9 \). Pour \( \sigma >1.0 \)
le résultat est très uniforme sur la sphère, comme le montre la valeur de l'ecart
type dans le tableau, mais le rayon est toujours surestimé. Remarquons que du
point de vue du détecteur de surfaces, les erreurs d'estimation du rayon dans
notre cas, traduisent simplement une erreur d'estimation de la \emph{position}
de la surface, qui résulte être biaisée dans la direction externe à la courbure
de la surface en considération. Les surfaces extraits présenteront, en conséquence,
des courbures plus importantes que celles de la surface réelle.

\begin{figure}
{\centering \includegraphics{data/OverUnderStimated.eps} \par}


\caption{\label{fig:OverUnderStimated}Changement de forme d'un contour comme conséquence
du biais dans l'estimation de la position des points détectés. La ligne pointillée
représente la sous-estimation. La ligne en tirets représente la sur-estimation.}
\end{figure}

La figure montre l'effet du biais de position dans l'aspect des surfaces extraites.


\subsubsection{Canny et Deriche}

Le coefficient \( \alpha  \) de l'opérateur de Canny et Deriche présente un
comportement inverse à celui de \( \sigma  \) du détecteur gaussien.

Les résultats montrent que le détecteur de Canny et Deriche est très stable
par rapport au choix du paramètre \( \alpha  \). Les valeurs élevées, minimisent
l'erreur d'estimation sans augmenter la variabilité de l'estimation. Les valeurs
testées pour ce détecteur ont été choisies de manière à produire des filtres
passe-bas d'étendue similaire à ceux utilisées pour les tests du filtre Gaussian.
La plage de variation des valeurs des deux paramètres peut être considérée comme
comparable.


\subsubsection{Shen et Castan}

Le filtre de Shen et Castan utilise le paramètre \( \alpha  \) correspondant
à la puissance de la fonction exponentielle du filtrage passe-bas. Plus la valeur
de \( \alpha  \) est importante, plus le filtre est étroit. Le rôle du paramètre
est équivalent à celui du détecteur de Canny et Deriche. La plage de valeurs
pour le paramètre \( \alpha  \) a été choisie pour produire des filtres passe-bas
similaires à ceux des autres méthodes.

Les résultats montrent que le détecteur de Shen et Castan, fournit une estimation
plus précise de la position de la surface que celle de Canny et Deriche. La
précision s'améliore pour les valeurs importantes de \( \alpha  \). La position
est décalée vers l'extérieur de la surface.


\subsubsection{Moments Géométriques}

Le détecteur des moments géométriques a été appliqué pour une suite de valeurs
de rayon de sa sphère de référence. Les valeurs du rayon de la sphère de test
ont tendance a être sous-estimées comme l'illustrent le tableau \ref{tab:MomentsTests}
et la figure \ref{fig:EstimationRayonMoments}, ce qui se traduit par un biais
dans l'estimation de la position de la surface vers la région interne de la
surface. La tendance à la sous estimation ne semble pas converger, ce qui nous
empêche d'envisager la recherche d'une valeur optimale du paramètre. Les bornes
de valeurs extrêmes sont de l'ordre de ceux de la méthode du filtre Gaussien
pour ses meilleurs valeurs de \( \sigma  \). Les valeurs élevées de l'erreur
pour les petits rayons indiquent une faible capacité à éliminer l'effet d'aliasing
naturel avec les voxels de l'image, conséquence logique de la taille réduite
des masques de convolution, cubes de l'ordre de 3 à 7 de côté.

Le temps de calcul de cette méthode est fonction de la taille de la sphère de
référence (voisinage), des valeurs illustratives sont présentées dans le tableau
\ref{tab:TempsCalculMoments}.

\begin{table}
{\centering \begin{tabular}{|c|c|c|c|c|c|c|}
\hline 
Rayon&
1.0&
1.5&
2.5&
3.5&
4.5&
5.5\\
\hline 
Temps (secs)&
182&
182&
446&
1066&
2053&
3469\\
\hline 
\end{tabular}\par}


\caption{\label{tab:TempsCalculMoments}Temps de calcul du processus de détection de
surfaces avec l'opérateur basé sur les Moments Géométriques, en fonction du
rayon de la sphère de référence.}
\end{table} 


\subsubsection{Le biais d'estimation en fonction de la courbure}

Il a été prouvé analytiquement que l'estimation de la position de la surface
fournie par le détecteur Gaussien est biaisé en fonction de la courbure de la
surface \cite{AuthenticatinZeroCrossing}. Des effets similaires ont été observés
dans d'autres types de détecteurs de surfaces \cite{Unbiased}. Nous avons effectue
une test pour analyser ce comportement pour les quatre détecteurs des surfaces
étudiés ici. Des sphères ont été synthétisées suivant le procédé décrit précédemment,
mais avec une suite de valeurs de rayons. Pour chacune de ses sphères le processus
de détection de surface a été appliqué avec chacun des méthodes. Comme le comportement
de chaque méthode de détection de surface dépend du choix de la valeur du paramètre,
nous avons retenu pour chacun des détecteurs la valeur de son paramètre qui
a fournit la meilleure estimation du rayon pour la sphère de 50 millimètres.
Ces paramètres doivent, en principe, être également optimaux pour les nouvelles
images. Ils sont présentés dans le tableau \ref{tab:MeilleursParametres}.

La conséquence de ce comportement dans l'extraction de formes serait, pour le
détecteur des Moments une réduction de détails conduisant à un lissage de la
surface, tandis que pour les autres détecteurs, apparaîtra un augmentation fictive
des détails de la surface, les courbures seront plus accentuées dans les surfaces
extraites par le détecteur Gaussien. Il faut retenir que dans toute cette analyse,
l'objet dans l'image est considéré être la région de niveau de gris le plus
élevé.

\begin{table}
{\centering \begin{tabular}{|c|c|c|}
\hline 
Méthode&
paramètre&
valeur\\
\hline 
\hline 
Laplacien d'une Gaussienne&
\( \sigma  \)&
0.8\\
\hline 
Canny et Deriche&
\( \alpha  \)&
4.0\\
\hline 
Shen et Castan&
\( \alpha  \)&
2.0\\
\hline 
Moments Géométriques&
\( R \)&
2.5\\
\hline 
\end{tabular}\par}


\caption{\label{tab:MeilleursParametres}Valeurs retenues comme optimales pour les tests
de performance des méthodes de détection sur des sphères synthétiques.}
\end{table}  Les résultats de la valeur moyenne du rayon pour chaque détecteur sont présentes
dans la figure \ref{fig:BiaisCourbureDetecteurs}. Nous pouvons remarquer que
tous les détecteurs sont d'autant plus biaisés que le rayon de courbure de la
surface est petit. L'erreur d'estimation s'approche de la taille du voxel (1
millimètre dans notre cas) quand le rayon de courbure tend vers 1, cet à dire
le détail minimum de l'image (sa résolution). 

Le détecteur Gaussien surestime le rayon, donc, déplace la position de la surface
vers l'extérieur. Le détecteur de Moments Géométriques sous estime le rayon,
ce qui équivaut à déplacer la position de la surface vers l'intérieur. Le détecteur
de Canny et Deriche montre un comportement assez similaire à celui du détecteur
de Shen et Castan, en sur estimant la valeur du rayon, mais avec un résultat
supérieur à celui du détecteur Gaussian.

La figure \ref{fig:BiaisCourbureStd} montre les écart-types des valeurs du
rayon estimé pour chacun des détecteurs en fonction du rayon de courbure de
la surface. Cet écart type peut être interprété comme une mesure de l'anisotropie
de la réponse du détecteur. Nous pouvons remarquer la stabilité du détecteur
des moments, sauf pour le plus petit rayon. Le détecteur Gaussien présente la
stabilité la plus haute, tandis que les détecteurs de Canny et Deriche présente
la variabilité la plus importante.

\begin{table*}
{\centering \begin{tabular}{|c|c|c|c|c|c|c|}
\hline 
\( \sigma  \)&
0.40&
0.60&
0.80&
1.00&
2.00&
4.00\\
\hline 
Rayon moyen&
52.1267&
50.3794&
50.0709&
50.0784&
50.1346&
50.3641\\
\hline 
Écart type du rayon&
0.1065&
0.0290&
0.0115&
0.0091&
0.0047&
0.0055\\
\hline 
Erreur quadratique&
4.5341&
0.1448&
0.0051&
0.0062&
0.0181&
0.1326\\
\hline 
Erreur moyen&
2.1267&
0.3794&
0.0708&
0.0784&
0.1346&
0.3641\\
\hline 
Écart type de l'erreur&
0.1065&
0.0290&
0.0115&
0.0091&
0.0047&
0.0055\\
\hline 
Décalage du centre (\( 10^{-6} \))&
43182&
1.173&
1.028&
2.086&
0.017&
0.2865\\
\hline 
Nombre de points&
174468&
206294&
203360&
203630&
204014&
206294\\
\hline 
Nombre de triangles&
277434&
412584&
407256&
407256&
408024&
412584\\
\hline 
Maximum&
52.5405&
50.4759&
50.1160&
50.1143&
50.1503&
50.3788\\
\hline 
Minimum&
51.9031&
50.3176&
50.0335&
50.0520&
50.1230&
50.3489\\
\hline 
Maximum du Gradient&
1004.23&
390.92&
146.42&
65.29&
4.69&
0.30\\
\hline 
\end{tabular}\par}


\caption{\label{tab:GaussianTests}Caractéristiques de l'estimation du rayon avec le
détecteur Gaussian}
\end{table*} 

\begin{table*}
{\centering \begin{tabular}{|c|c|c|c|c|c|c|}
\hline 
\( \alpha  \)&
0.50&
0.80&
1.00&
2.00&
4.00&
8.00\\
\hline 
Rayon moyen&
50.2248&
50.1062&
50.0787&
50.0426&
50.0349&
50.0341\\
\hline 
Écart type du rayon&
0.0783&
0.0330&
0.0230&
0.0141&
0.0156&
0.0161\\
\hline 
Erreur quadratique&
0.0567&
0.0124&
0.0067&
0.0020&
0.0015&
0.0014\\
\hline 
Erreur moyen&
0.2248&
0.1062&
0.0787&
0.0426&
0.0349&
0.0341\\
\hline 
Écart type de l'erreur&
0.0783&
0.0330&
0.0230&
0.0141&
0.0156&
0.0161\\
\hline 
Décalage du centre (\( 10^{-6} \))&
0.3910&
1.177&
1.448&
0.384&
0.145&
2.726\\
\hline 
Nombre de points&
204830&
203606&
203486&
203486&
203294&
203294\\
\hline 
Nombre de triangles&
409656&
407208&
406968&
406968&
406584&
406584\\
\hline 
Maximum&
50.3221&
50.1556&
50.1196&
50.0794&
50.0827&
50.0845\\
\hline 
Minimum&
49.9668&
49.9941&
49.9952&
49.9794&
49.9654&
49.9626\\
\hline 
Maximum du Gradient&
191.39&
188.95&
186.42&
176.66&
192.20&
203.09\\
\hline 
\end{tabular}\par}


\caption{\label{tab:CannyDericheTests}Caractéristiques de l'estimation du rayon avec
le détecteur de Canny et Deriche}
\end{table*} 

\begin{table*}
{\centering \begin{tabular}{|c|c|c|c|c|c|c|}
\hline 
\( \alpha  \)&
0.30&
0.40&
0.50&
1.00&
2.00&
4.00\\
\hline 
Rayon moyen&
50.0955&
50.0755&
50.0638&
50.0422&
50.0337&
50.0313\\
\hline 
Écart type du rayon&
0.0213&
0.0184&
0.0167&
0.0144&
0.0159&
0.0176\\
\hline 
Erreur quadratique&
0.0096&
0.0060&
0.0043&
0.0020&
0.0014&
0.0013\\
\hline 
Erreur moyen&
0.0955&
0.0755&
0.0638&
0.0422&
0.0337&
0.0313\\
\hline 
Écart type de l'erreur&
0.0213&
0.0184&
0.0166&
0.0144&
0.0159&
0.0176\\
\hline 
Décalage du centre (\( 10^{-6} \))&
1.658&
0.5221&
0.0111&
0.3928&
0.2697&
0.4547\\
\hline 
Nombre de points&
203822&
203726&
203678&
203390&
203342&
203294\\
\hline 
Nombre de triangles&
407640&
407448&
407352&
406776&
406680&
406584\\
\hline 
Maximum&
50.1862&
50.1565&
50.1386&
50.1077&
50.1028&
50.1041\\
\hline 
Minimum&
50.0535&
50.0362&
50.0258&
50.0041&
49.9889&
49.9785\\
\hline 
Maximum du Gradient&
182.75&
184.72&
184.73&
179.52&
192.55&
202.03\\
\hline 
\end{tabular}\par}


\caption{\label{tab:ShenCastanTests}Caractéristiques de l'estimation du rayon avec
le détecteur de Shen et Castan.}
\end{table*} 

\begin{table*}
{\centering \begin{tabular}{|c|c|c|c|c|c|c|}
\hline 
\( R \) sphère de référence&
1.0&
1.5&
2.5&
3.5&
4.5&
5.5\\
\hline 
Rayon moyen&
49.9785&
49.9662&
49.9492&
49.9204&
49.881&
49.831\\
\hline 
Écart type du rayon&
0.0526&
0.0476&
0.0195&
0.0117&
0.0077&
0.0054\\
\hline 
Erreur quadratique&
0.0032&
0.0035&
0.0030&
0.0065&
0.0142&
0.0286\\
\hline 
Erreur moyen&
-0.0215&
-0.0358&
-0.0508&
-0.0796&
-0.1190&
-0.1690\\
\hline 
Écart type de l'erreur&
0.0526&
0.0476&
0.0195&
0.0117&
0.0077&
0.0054\\
\hline 
Décalage du centre (\( 10^{-6} \))&
1.094&
0.3735&
0.5735&
0.4671&
0.7886&
0.6463\\
\hline 
Nombre de points&
202742&
202598&
202598&
202358&
202166&
201974\\
\hline 
Nombre de triangles&
405480&
405192&
405192&
404712&
404328&
403944\\
\hline 
Maximum&
50.1562&
50.1465&
50.0176&
49.9599&
49.9077&
49.8505\\
\hline 
Minimum&
49.7708&
49.7698&
49.8785&
49.8813&
49.8553&
49.8138\\
\hline 
Maximum du Gradient&
26.33&
33.30&
42.06&
45.60&
47.24&
48.11\\
\hline 
\end{tabular}\par}


\caption{\label{tab:MomentsTests}Caractéristiques de l'estimation du rayon avec le
détecteur de Moments Géométriques.}
\end{table*} 

\begin{figure}
{\centering \resizebox*{8cm}{6cm}{\includegraphics{LoG/EstimationRayon.eps}} \par}


\caption{\label{fig:EstimationRayonGauss}Erreur d'estimation du rayon de la sphère
avec le détecteur Gaussien en fonction du paramètre sigma. Les barres représentent
les valeurs minimale et maximale de l'estimation (les valeurs sont prises du
tableau \ref{tab:GaussianTests}).}
\end{figure}

\begin{figure}
{\centering \resizebox*{8cm}{6cm}{\includegraphics{CannyDeriche/EstimationRayon.eps}} \par}


\caption{\label{fig:EstimationRayonCannyDeriche}Erreur d'estimation du rayon de la
sphère avec le détecteur de Canny et Deriche en fonction du paramètre \protect\( \alpha \protect \).
Les barres représentent les valeurs minimale et maximale de l'estimation (les
valeurs sont prises du tableau \ref{tab:CannyDericheTests}).}
\end{figure}

\begin{figure}
{\centering \resizebox*{8cm}{6cm}{\includegraphics{ShenCastan/EstimationRayon.eps}} \par}


\caption{\label{fig:EstimationRayonShenCastan}Erreur d'estimation du rayon de la sphère
avec le détecteur de Shen et Castan en fonction du paramètre \protect\( \alpha \protect \).
Les barres représentent les valeurs minimale et maximale de l'estimation (les
valeurs sont prises du tableau \ref{tab:ShenCastanTests}).}
\end{figure}

\begin{figure}
{\centering \resizebox*{8cm}{6cm}{\includegraphics{Moments/EstimationRayon.eps}} \par}


\caption{\label{fig:EstimationRayonMoments}Erreur d'estimation du rayon avec le détecteur
de Moments Géométriques en fonction du rayon de la sphère de référence (voisinage).
Les barres représentent les valeurs minimale et maximale de l'estimation (les
valeurs sont prises du tableau \ref{tab:MomentsTests}).}
\end{figure}\begin{figure}
{\centering \resizebox*{8cm}{6cm}{\includegraphics{data/BiaisCourbure.eps}} \par}


\caption{\label{fig:BiaisCourbureDetecteurs}Erreur d'estimation de la position de la
surface en fonction de son rayon de courbure pour chacun des détecteurs.}
\end{figure}\begin{figure}
{\centering \resizebox*{8cm}{6cm}{\includegraphics{data/BiaisCourbureStd.eps}} \par}


\caption{\label{fig:BiaisCourbureStd}Écart type de l'erreur d'estimation de la position
de la surface en fonction de son rayon de courbure pour chacun des détecteurs.}
\end{figure}




\subsubsection{Temps de calcul}

Les tests ont été effectués sur un plateforme hors réseaux, avec les caracteristiques
suivantes :

\begin{itemize}
\item Pentium MMX 200 MHz
\item 128 Mega Octets RAM
\item Disque swap 64 Mega Octets, bus IDE
\item Disque data 6 Giga Octets, bus IDE
\item Carte graphique 3Dfx Voodoo2
\item Système Operative Linux 2.0.18
\item Compilateur GNU C++, egcs 1.0.3
\end{itemize}
Les temps ont été chronométrés par l'utilisateur. Ils sont approximatifs car
certains processus ont nécessité du swapping de la mémoire en disque. Ils sont
en tout cas représentatifs du temps (humain) qu'un utilisateur doit dédier à
cette tâche. 

Les temps de filtrage de chaque méthode sont reportés dans le tableau \ref{tab:TempsDetectionFilters}.
Pour la méthode des moments géométriques ils comprennent la génération des masques
de corrélation. Dans ce cas, le temps de calcul dépends de la taille du voisinage
choisi, plus précisement du cube du rayon de la sphère de référence. Pour les
autres méthodes, ces temps ne dépendent pas de la valeur du paramètre grâce
à leur mise en oeuvre récursive.

Le temps de calcul du processus global de traitement d'un volume de données,
comprenant: lecture du volume de données, détection, extraction, sauvegarde
et affichage de la surface, est détaille dans la table \ref{tab:DetectionTimming}.
Comme le temps du filtrage dépendant de la méthode utilisé, le temps du filtrage
Gaussian a été utilisée ici comme représentatif.

\begin{table}
{\centering \begin{tabular}{|c|c|}
\hline 
Méthode&
temps (secs)\\
\hline 
\hline 
Laplacien d'une Gaussienne&
80\\
\hline 
Canny et Deriche&
52\\
\hline 
Shen et Castan&
32\\
\hline 
Moments Géométriques&
\( \approx  \)1000\\
\hline 
\end{tabular}\par}


\caption{\label{tab:TempsDetectionFilters}Temps de calcul des méthodes de détection.}
\end{table}  

\begin{table}
{\centering \begin{tabular}{|c|c|}
\hline 
Tâches&
temps (secs)\\
\hline 
\hline 
Lecture du volume de données&
2\\
\hline 
Filtrage de détection (filtre Gaussien)&
80\\
\hline 
conversion BCC Gradient&
9\\
\hline 
conversion BCC Laplacien&
9\\
\hline 
Seuillage bas (test utilisateur)&
3\\
\hline 
Préparation extraction&
8\\
\hline 
Détection de points (BCC marching cubes)&
62\\
\hline 
Vérifications topologiques&
45\\
\hline 
Sauvegarde en disque&
20\\
\hline 
Lecture du disque&
25\\
\hline 
Rendu de surface &
9\\
\hline 
\hline 
Total&
272\\
\hline 
\end{tabular}\par}


\caption{\label{tab:DetectionTimming}Temps de calcul détaillé des processus de détection
et d'extraction de surface.}
\end{table} L'évaluation de temps de calcul doit être considéré comme purement indicatif,
car il dépend de la qualité de la programmation et de la bonne configuration
de la plateforme utilisé.


\subsection{L'estimation de la normale à la surface}

Les détecteurs de surfaces utilisés dans notre étude peuvent fournir une estimation
de la direction de la normale à la surface. Pour l'analyser, chaque détecteur
a été appliqué avec la valeur du paramètre trouvée comme optimale pour la sphère
de rayon 50 millimètres. 

\begin{figure}
{\centering \resizebox*{8cm}{6cm}{\includegraphics{data/VerifyNormal.eps}} \par}


\caption{\label{fig:VerifyNormalMax}Valeurs extrêmes de l'erreur d'estimation de la
normale à la surface en fonction du rayon de courbure.}
\end{figure}\begin{figure}
{\centering \resizebox*{8cm}{6cm}{\includegraphics{data/VerifyNormalStd.eps}} \par}


\caption{\label{fig:VerifyNormalStd}Valeurs moyennes de l'erreur d'estimation de la
normale à la surface en fonction du rayon de courbure.}
\end{figure}

L'estimation de la normale est faite au centre de chaque voxel. Pour obtenir
un résultat représentatif pour l'ensemble de la sphère, une bande autour de
la surface a été définie. Cette bande est formée par tous les points dont le
module du gradient excède \( \frac{1}{10} \) de la valeur maximale du module
du gradient. Le vecteur normal à la surface a été normalisé pour tous les voxels
à l'intérieur de cette bande et le produit scalaire avec le vecteur théorique
a été calculé. L'erreur d'orientation du vecteur normal en degrés est estimée
à partir de la valeur du produit scalaire. Les valeurs maximale et moyenne de
ces angles sont reportées ici comme mesure représentative de la bonne ou mauvaise
correlation de l'orientation de l'ensemble des vecteurs normales. 

La figure \ref{fig:VerifyNormalMax} présente les valeurs extrêmes de l'erreur
d'orientation de la normale. La figure \ref{fig:VerifyNormalStd} illustre les
valeurs moyennes. Le détecteur de Moments Géométriques est le plus performant
et se montre relativement insensible à la courbure de la surface. Le détecteur
Gaussien suit un comportement similaire mais à partir des rayons de courbures
de 10 millimètres. La réponse du détecteur de Shen et Castan parait similaire
à celle du détecteur de Canny et Deriche. Ces deux derniers ont de faibles performances
en l'estimation de l'orientation de la surface. Ceci est dû au fait d'avoir
été construit comme le produit tensoriel des filtres \( 1D \).

Étant donnée que l'estimation de la normale est faite pour chacun des voxels,
elle sera plus ou moins exacte en fonction de la distance du voxel à la surface.
La bonne orientation du vecteur est associée ici à une polarisation, à l'image
de l'aiguille d'une boussole. En faisant varier la largeur de la bande il est
possible d'étudier la perte de polarisation du détecteur en fonction de la distance
à la surface. Nous avons trouvée que l'estimation est acceptable pour des seuils
de l'ordre de 0.01 de la valeur maximale. 


\subsection{La précision de la détection}

L'évaluation des performances des différentes méthodes de détection de surfaces
n'est pas une tâche simple, car la validité d'une méthode est fonction de l'utilisation
envisagée pour le surface.

A l'heure actuelle, la plupart d'études comparatives des méthodes de détection
de contours reposent sur le critère d'observateurs humains \cite{ComparingMethods}.
Ce qui implique une orientation à la perception visuelle plus que à l'utilisation
pour de subséquents traitements informatiques. Notre approche ici, prétend être
plus objective, car il est basée en l'évaluation de paramètres quantitatives
independents d'un observateur particulier.

Il est à regretter néanmoins, dans la majorité des cas, l'absence d'une connaissance
de la réalité physique (géométrique) des objets analysés. Les comparaisions
sont donc réalisées sur des images synthétiques, dont la liason avec la réalité
peut difficilement être établie. A l'égale que dans la plupart des méthodologies
d'imagerie médical, c'est bien notre cas ici, car la \emph{vérité de du terrain}
n'est presque jamais accessible.


\section{Discussion}


\subsection{La relation entre l'objet et l'image}

L'utilisation des détecteurs de surfaces comme des mécanismes de mis en évidence
de la présence d'un objet physique, suppose l'existence d'une relation directe
entre la nature de l'objet réel et le paramètre physique qui a été mesuré pour
le convertir en niveau de gris dans l'image. Cette relation est souvent oubliée,
au point de confondre l'image discrète avec l'objet physique. Il faut donc,
remarquer : \emph{l'image n'est pas l'objet} \cite{PhysicsMedicalImaging}.

Il a été bien établi que la performance des méthodes de détection de surfaces
dépend du contenu de l'image. Le choix des paramètres optimaux du détecteur,
ainsi que la signification même de ce qu'est un surface et ce qui ne l'est pas,
sont fonction du type d'information cherchée dans l'image. La qualité de la
détection de surface ne peut être, en conséquence, un objectif a atteindre \emph{per
se}, tout au contraire, sa qualité doit être évaluée dans le contexte d'une
chaîne de traitement d'information encadré dans une application précise \cite{ComparingMethods}.


\subsection{L'application a l'imagerie osseuse}

Les structures osseuses sont été étudies à l'aide des rayons X car les substances
inorganiques minérales présentes dans les tissus osseux sont fortement absorbantes
des radiations dans ce domaine d'énergie. Strictement ce qu'on observe dans
l'image de rayon X est une estimation du coefficient d'absorption du matériau. 

Néanmoins, l'os en tant que structure anatomique n'est seulement le tissu minéralisé,
il comporte aussi des zones cartilagineuses est fibreuses non minéralisés. Dans
ce contexte, le contenu d'information du volume de données est loin d'être suffisant
pour déterminer la forme d'une structure osseuse fonctionelle. La reconstruction
d'une telle structure à partir d'une image, doit prendre en compte des connaissances
anatomiques (particulièrement hystologiques) relatives à sa constitution et
à sa morphologie. Les méthodes de détection de surfaces aident à obtenir des
informations pertinentes pour la reconstruction de l'objet, mais en aucune manière,
ces information sont suffisantes pour servir de définition de l'objet.


\section{La partialité de l'information}

Une des difficultés rencontrées lors du développement de procédures de détection
de surfaces est la grande séparation existante entre les notions intuitives
définissant le concept de surface et la véritable réalisation du signal.

L'aspect plus caracteristique dans les cas des images médicales est la variation
progressive et continue du contraste qui fait disparaître un surface noyé dans
le niveau de bruit du signal. Typiquement, cette difficulté est surmontée avec
l'approche du seuillage par hystéresis. Bien si ce seuillage permet d'aumenter
considérablement la netteté des surfaces et d'étendre son suivi, il ne peut
pas se substituer la conception de l'objet au déla de l'information contenue
dans l'image.

Notre conclusion dans ce point là, est toute simplement, que l'image et loin
d'être complète. Pour cette raison nous dirigeons nos efforts en direction de
la modélisation des structures osseuses afin de disposer des ces informations
anatomiques indispensables pour la compréhension de l'information partielle
contenue dans les volumes des données.

\begin{thebibliography}{}
\bibitem{MomentOtherProfiles}S. Ghosal, R.Mehrotra, A Moment-Based Unified Approach to Image Feature Detection,
IEEE Transactions on Image Processing, Vol 6. No 6, June 1997. pp 781-793.
\bibitem{MomentsFast}L. Yang, R. Albregtsen, T. Taxt, Fast Computation of Three-Dimensional Geometric
Moments Using a Discrete Divergence Theorem and a Generalization to Higher Dimensions,
Graphical Models and Image Processing, Vol. 59, No. 2, March, pp. 97-108, 1997.
\bibitem{Deriche}R. Deriche, Fast Algorithms for Low-Level Vision, IEEE Transactions on Pattern
Analysis and Machine Intelligence, Vol. 12, No. 1, January 1990, pp 78-87.
\bibitem{CastanZaoShen}S. Castan, J. Zhao, J. Shen, A Family of Edge Detection Operators Based on the
Optimal Exponential Filter.
\bibitem{ShenCastan}J. Shen, S. Castan, An Optimal Linear Operator for Edge Detection, in Proc.
CVPR, Miami, FL, June 1986, pp. 109-114.
\bibitem{CompositeEdges}S. Ghosal, R. Mehrotra, Detection of Composite Edges, IEEE Transactions on Image
Processing, Vol 3, No. 1, January 1994, pp 14-25.
\bibitem{HuertasMedioni}A. Huertas, G. Medioni, Detection of Intensity Changes with Subpixel Accuracy
Using Laplacian-Gaussian Masks, IEEE Transactions on Pattern Analysis and Machine
Intelligence, Vol PAMI-8, No. 5, september 1986, pp 651-664.
\bibitem{ZeroCrossEdgeDetect}R. Mehrotra, S. Zhan, A Computational Approach to Zero-Crossing-Based Two-Dimensional
Edge Detection, Graphical Models and Image Processing, Vol. 58, No. 1, January,
pp. 1-17, 1996.
\bibitem{OptimalEdgeDetect}R. J. Qian, T. S. Huang, Optimal Edge Detection in Two-Dimensional Images, IEEE
Transactions on Image Processing, Vol. 5, No. 7, July 1996.
\bibitem{Operator1Dto2D}M. Azaria, I. Vitsnudel, Y. Y. Zeevi, The Design of Two-Dimensional Gradient
Estimators Based on One-Dimensional Operators, IEEE Transactions on Image Processing,
Vo. 5, No. 1, January 1996, pp 155-159.
\bibitem{MarrHildreth}D. Marr, E. Hildreth, Theory of edge detection, Proc. Roy. Soc. London, Vol.
B207, pp. 187-217, 1980.
\bibitem{Marr}D. Marr, Vision, ed. W.H.Freeman and co.
\bibitem{MomentOperator3D}L. M. Luo, Ch. Hamitouche, J. L. Dillenseger, J. L. Coatrieux, A Moment-Based
Three-Dimensional Edge Operator, IEEE Transactions on Biomedical Engineering,
Vol. 40, No. 7\c{ } July 1993\c{ } pp 693-703.
\bibitem{Hamitouche2}Ch. Hamitouche, C. Roux, J.L. Coatrieux, Design of New Surface Detection Operators
in the Case of an Anisotropic Sampling of 3D Volume Data, Computer Vision, Virtual
Reality and Robotics in Medicine, CVRMed'95, Lecture Notes in Computer Science
905, Springer Verlag, pp 523-532.
\bibitem{MomentOperator2D}E. P. Lyvers, O.R. Mitchell, M.L. Akey, A.P. Reeves, Subpixel Measurements Using
a Moment-Based Edge Operator, IEEE Transactions on Pattern Analysis and Machine
Intelligence, Vol. 11, No. 12, december 1989. pp. 1293-1309.
\bibitem{GaussienRecursive}R. Deriche, Recursively Implementing the Gaussian and its Derivatives, reseach
repport no.1893, avril 1993, Unité de recherche INRIA Sophia-Antipolis, http://www.inria.fr.
\bibitem{PhysicsMedicalImaging}S. Webb, The Physics of Medical Imaging, Medical Science Series, IOP Publishing
ltd, 1988.
\bibitem{HermanRFP}G.T. Herman, Image Reconstruction from Projections, The Fundamentals of Computerized
Tomograhy\c{ } Academic Press, 1980.
\bibitem{Herman3Dimaging}J.K. Udupa, G.T. Herman, 3D Imaging in Medicine, CRC Press, 1989.
\bibitem{ScaleSpaceMedians}J.A. Bangham, P. Ling, R. Young, Multiscale Recursive Medians, Scale-Space,
and Transforms with Applications to Image Processing, IEEE Transactions on Image
Processing, Vol. 5, No. 6, June 1986, pp. 1043-1048.
\bibitem{GradientWatersheds}P. T. Jackway, Gradient Watersheds in Morphological Scale-Space, IEEE Transactions
on Image Processing, Vol. 5, No. 6, June 1986, pp. 913-921.
\bibitem{ScalingTheoZeroCross}A.L. Yuille, T.A. Poggio, Scaling Theorems for Zero Crossings, IEEE Transactions
on Pattern Analysis and Machine Intelligence, Vol. PAMI-8, No. 1, January 1986,
pp. 15-25.
\bibitem{ZeroCrossRepresentation}R. A. Hummel, Representations based on Zero-crossings in Scale-Space, IEEE Computer
Society Conference on Computer Vision and Pattern Recognition, Proceedings CVPR'86,
IEEE Computer Society Press, 1986, pp. 204-209.
\bibitem{UniquenessGaussian}J. Babaud, A. P. Witkin, M. Baudin, R.O. Duda, Uniqueness of the Gaussian Kernel
for Scale-Space Filtering, IEEE Transactions on Pattern Analysis and Machine
Intelligence, Vol. PAMI-8, No. 1, January 1986, pp. 26-33.
\bibitem{AuthenticatinZeroCrossing}J.J. Clark, Authenticating Edges Produed by Zero-Crossing Algorithms, IEEE Transactions
on Pattern Analysis and Machine Intelligence, Vol. 11, No. 1, January 1989,
pp. 43-57.
\bibitem{ScaleSpaceConvexShapes}S. Sengupta, S.C. Sahasrabudhe, Scale space displacement of zero-crossing of
\( \nabla ^{2}G \) operated images for convex bodies and convex sets, Signal
Processing, Vol 47, 1995, Elsevier Science, pp. 279-285.
\bibitem{ScaleSpaceStability}W.F. Bischof, T. Caelli, Parsing Scale-Space and Spatial Stability Analysis,
Computer Vision, Graphics and Image Processing, Vol. 42, 1988, pp. 192-205.
\bibitem{ScaleSpaceLigaments}Z.Q. Liu, R.M. Rangayyan, C.B. Frank, Statistical Analysis of Collagen Alignement
in Ligaments by Scale-Space Analysis, IEEE Transactions on Biomedical Engineering,
Vol. 38, No. 6, June 1991, pp. 580-587.
\bibitem{DirectionalAnalysisScaleSpace}Z.Q. Liu, R.M. R. Rangayyan, C.B. Frank, Directional Analysis of Images in Scale
Space, IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol.
13, No. 11, november 1991, pp. 1186-1192.
\bibitem{29}F. Mokhtarian, A. Mackworth, Scale-Based Description and Recognition of Planar
Curves and Two-Dimensional Shapes, IEEE Transactions on Pattern Analysis and
Machine Intelligence, Vol. PAMI-8, No. 1, january 1986, pp. 34-43.
\bibitem{INRIA2}O. Monga, S. Benayoun, Using Partial Derivatives of 3D Images to Extract Typical
Surface Features, Rappor de Recherche 1599, INRIA, février 1992. 
\bibitem{INRIA3}O. Monga, N. Ayache, P. T. Sander, From voxel to curvature, Rapport de Recherche
1356, INRIA, decembre 1990.
\bibitem{Canny}J. Canny, A computational approach to edge detection, IEEE Transactions on Pattern
Analysis and Machine Intelligence, Vol. PAMI-8, No. 6, Novembre 1986, pp. 679-698.
\bibitem{DericheRecursive}R. Deriche, Fast algorithms for low level vision, IEEE Transactions on Pattern
Analysis and Machine Intelligence, Vol. 12, No. 1, 1990, pp. 78-87.
\bibitem{3DEdgeDetecRecurFilt}O. Monga, R. Deriche, J.M. Rocchisani, 3D edge detection using recursive filtering:
Application to scanner images, Computer Vision Graphics and Image Processing,
Vol. 53, No. 1, pp. 76-87, January 1991.
\bibitem{35}P. T. Sander, S. W. Zucker, Inferring surface trace and differential structure
from 3D images. IEEE Transactions on Pattern Analysis and Machine Intelligence,
Vol. 12, No. 9, September 1990.
\bibitem{3DSymmetryCurvature}A. Yuille, M. Leyton, 3D Symmetry-curvature duality theorems, Computer Vision,
Graphics, and Image Processing, Vol. 52, pp 124-140, 1990.
\bibitem{ZuckerHummel}S.W. Zucker, R. M. Hummel, A three dimensional edge operator. IEEE Transactions
on Pattern Analysis and Machine Intelligence, Vol. PAMI-3, No. 3, May 1981,
pp. 324-331.
\bibitem{38}P.T. Sander, S.W. Zucker, Singularities of principal direction fields from 3D
images. IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-14,
No. 3, March 1992, pp. 309-317.
\bibitem{39}P.T. Sander, S.W. Zucker, Inferring surface trace and differential structure
from 3D images, IEEE Transactions on Pattern Analysis and Machine Intelligence,
Vol. 12, No. 9, September 1990.
\bibitem{FFTalgo}D. F. Elliot, K. R. Rao, Fast Transforms, Algorithms, analyses, applications,
Academic Press 1982.
\bibitem{Rosenfeld}A.Rosenfeld, A. Kak, \textit{Digital picture processing,} Academic Press Inc.,
1982.
\bibitem{DungeonMersereau}D.E.Dudgeon, R.M. Mersereau \textit{Multidimensional digital signal processing}
Prentice-Hall, Englwood Cliffs; NJ; 1984.
\bibitem{MuPAD}MuPAD, Multiprocessing Algebra Data Tool\c{ } SciFace software GmbH, http://www.mupad.de,
ftp.mupad.de. Université de Padenbourg.
\bibitem{ComparingMethods}M. Heath, S. Sarkar\c{ }T. Sanocki, K. Bowyer, Comparision of Edge Detectors,
Computer Vision and Image Understanding, Vol. 69, No. 1, January 1998, pp. 38-54.
\bibitem{ZuckerSigmoide}J.H. Elder, S.W. Zucker, Local Scale Control for Edge Detection and Blur Estimation,
IEEE Trans. on Pattern Analysis and Machine Intellignece, Vol. 20, No. 7, July
1998, pp. 699-716.
\bibitem{MarchingCubes}W.E. Lorensen, H.E. Cline, Marching Cubes: A High Resolution 3D Surface Construction
Algorithm, Computer Graphics, Vol. 21, No. 4, pp.163-169, 1987.
\bibitem{Ibanez96}L. Ibáñez, C. Hamitouche, C. Roux, \textit{\emph{``Determination of Discrete
Sampling Grids with Optimal Topological and Spectral Properties'',}} \emph{Proc.
6th International Workshop in Discrete Geometry for Computer Imagery DGCI96,}
Lecture Notes in Computer Science 1176, Springer Verlag, Lyon, France, pp. 181-192,
1996.
\bibitem{ICIP96}L. Ibáñez, C. Hamitouche, C. Roux \textit{Moment-based operator for sub-voxel
surface extraction in medical imaging} International Conference on Image Processing
ICIP'96, Lausanne, Switzerland, September 1996.
\bibitem{HermanSummerSchool}G.T. Herman, ``Biomedical Applications of Digital Geometry'', \emph{Third
IEEE-EMBS International Summer School}, Berder Island, Brittany, France, June
1998.
\bibitem{GraphTheory}J.L. Gross, Th.W. Tucker, \emph{Topological Graph Theory}, John Wiley \& Sons,
1987.
\bibitem{Unbiased}C. Steger, An Unbiased Detector of Curvilinear Structures, IEEE Trans. on Pattern
Analysis and Machine Intelligence, Vol. 20, No. 2, pp.113-125, 1998.
\bibitem{DirectionalFiltering}A.P. Papli\'{n}ski, Directional Filtering in Edge Detection, IEEE Trans. on
Image Processing, Vol. 7, No. 4, pp.611-615. 1998
\end{thebibliography}
\end{document}
